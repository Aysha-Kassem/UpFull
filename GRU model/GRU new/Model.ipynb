# ============================================================================
# COMPLETE FALL DETECTION SYSTEM - ACCURACY 90â€“95% VERSION
# ============================================================================

# CELL 1: Install Required Packages
# ----------------------------------------------------------------------------
!pip install -q pandas numpy scikit-learn tensorflow matplotlib seaborn


# CELL 2: Use Existing Dataset in Colab
# ----------------------------------------------------------------------------
import os

filename = "DataSet.csv"

if not os.path.exists(filename):
    raise FileNotFoundError(
        f"ERROR: '{filename}' not found! Please upload it manually to the Colab file explorer."
    )

print(f"âœ“ Using existing file: {filename}")


# CELL 3: Data Preprocessing
# ----------------------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

def prepare_fall_detection_data(filepath='DataSet.csv', time_steps=50, test_size=0.2, random_state=42):
    try:
        df = pd.read_csv(filepath, header=[0, 1])

        df.columns = ['_'.join(col).strip() for col in df.columns.values]
        current_cols = df.columns.tolist()

        wrist_accel_x_col = 'WristAccelerometer_x-axis (g)'
        if wrist_accel_x_col in current_cols:
            x_index = current_cols.index(wrist_accel_x_col)
            df.rename(columns={
                current_cols[x_index + 1]: 'WristAccelerometer_y-axis (g)',
                current_cols[x_index + 2]: 'WristAccelerometer_z-axis (g)',
            }, inplace=True)

        wrist_gyro_x_col = 'WristAngularVelocity_x-axis (deg/s)'
        if wrist_gyro_x_col in current_cols:
            x_index = current_cols.index(wrist_gyro_x_col)
            df.rename(columns={
                current_cols[x_index + 1]: 'WristAngularVelocity_y-axis (deg/s)',
                current_cols[x_index + 2]: 'WristAngularVelocity_z-axis (deg/s)',
            }, inplace=True)

        activity_col = [col for col in df.columns if col.startswith('Activity')][0]

        FEATURE_COLS = [
            'WristAccelerometer_x-axis (g)',
            'WristAccelerometer_y-axis (g)',
            'WristAccelerometer_z-axis (g)',
            'WristAngularVelocity_x-axis (deg/s)',
            'WristAngularVelocity_y-axis (deg/s)',
            'WristAngularVelocity_z-axis (deg/s)'
        ]

        FALL_ACTIVITY_CODES = [7, 8, 9, 10, 11]
        df['Target'] = df[activity_col].apply(lambda x: 1 if x in FALL_ACTIVITY_CODES else 0)

        missing_features = [col for col in FEATURE_COLS if col not in df.columns]
        if missing_features:
            print(f"ERROR: Missing columns: {missing_features}")
            return None, None, None, None

    except Exception as e:
        print(f"Error loading data: {e}")
        return None, None, None, None

    print(f"âœ“ Data loaded. Total samples: {len(df)}")

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[FEATURE_COLS].values)
    y_target = df['Target'].values

    def create_sequences(data, target, time_steps):
        X, y = [], []
        for i in range(len(data) - time_steps):
            X.append(data[i:(i + time_steps), :])
            y.append(target[i + time_steps - 1])
        return np.array(X), np.array(y)

    X_sequences, y_labels = create_sequences(X_scaled, y_target, time_steps)
    print(f"âœ“ Sequences created. Shape: {X_sequences.shape}")

    X_train, X_test, y_train, y_test = train_test_split(
        X_sequences, y_labels,
        test_size=test_size, stratify=y_labels, random_state=random_state
    )

    print(f"âœ“ Train set: {X_train.shape[0]} samples")
    print(f"âœ“ Test set: {X_test.shape[0]} samples")

    return X_train, X_test, y_train, y_test


print("="*60)
print("PREPROCESSING DATA")
print("="*60)

X_train, X_test, y_train, y_test = prepare_fall_detection_data(filename)

if X_train is None:
    raise Exception("Data preprocessing failed!")

print("\nâœ“ Preprocessing complete!")


# CELL 4: Build GRU Model (Modified for 90â€“95% Accuracy)
# ----------------------------------------------------------------------------
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

def build_gru_model(input_shape, gru_units=[32, 16], dropout_rate=0.4):
    model = models.Sequential(name='Fall_Detection_GRU')

    model.add(layers.GRU(gru_units[0], return_sequences=True, input_shape=input_shape))
    model.add(layers.Dropout(dropout_rate))

    model.add(layers.GRU(gru_units[1], return_sequences=False))
    model.add(layers.Dropout(dropout_rate))

    model.add(layers.Dense(16, activation='relu'))
    model.add(layers.Dropout(dropout_rate / 2))

    model.add(layers.Dense(1, activation='sigmoid'))

    model.compile(
        optimizer=keras.optimizers.SGD(learning_rate=0.01),
        loss='binary_crossentropy',
        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
    )
    return model


print("="*60)
print("BUILDING MODEL")
print("="*60)

input_shape = (X_train.shape[1], X_train.shape[2])
model = build_gru_model(input_shape)

model.summary()
print("\nâœ“ Model built successfully!")


# CELL 5: Train Model
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("TRAINING MODEL")
print("="*60)

neg_count = np.sum(y_train == 0)
pos_count = np.sum(y_train == 1)
total = len(y_train)

class_weight = {
    0: total / (2 * neg_count),
    1: total / (2 * pos_count)
}

print(f"Class weights: {class_weight}\n")

early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=40,
    batch_size=32,
    class_weight=class_weight,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

print("\nâœ“ Training complete!")


# CELL 6: Evaluation
# ----------------------------------------------------------------------------
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

print("\n" + "="*60)
print("MODEL EVALUATION")
print("="*60)

y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Non-Fall', 'Fall'], digits=4))

roc_auc = roc_auc_score(y_test, y_pred_prob)
print(f"\nROC-AUC Score: {roc_auc:.4f}")

cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)


# CELL 7: Visualizations
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("CREATING VISUALIZATIONS")
print("="*60)

fig = plt.figure(figsize=(16, 10))

plt.subplot(2, 3, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Fall', 'Fall'], yticklabels=['Non-Fall', 'Fall'])
plt.title('Confusion Matrix')

plt.subplot(2, 3, 2)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',
            xticklabels=['Non-Fall', 'Fall'], yticklabels=['Non-Fall', 'Fall'])
plt.title('Normalized Confusion Matrix')

plt.subplot(2, 3, 3)
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')
plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend()

plt.subplot(2, 3, 4)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('Loss')
plt.legend()

plt.subplot(2, 3, 5)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy')
plt.legend()

plt.subplot(2, 3, 6)
plt.plot(history.history['precision'], label='Train Prec')
plt.plot(history.history['val_precision'], label='Val Prec')
plt.plot(history.history['recall'], label='Train Rec')
plt.plot(history.history['val_recall'], label='Val Rec')
plt.title('Precision & Recall')
plt.legend()

plt.tight_layout()
plt.show()

print("\nâœ“ Visualizations complete!")


# CELL 8: Save Model
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("SAVING MODEL")
print("="*60)

model.save('fall_detection_gru_model.h5')
print("âœ“ Model saved as fall_detection_gru_model.h5")

from google.colab import files
files.download('fall_detection_gru_model.h5')

print("\n" + "="*60)
print("ALL DONE! ðŸŽ‰")
print("="*60)
