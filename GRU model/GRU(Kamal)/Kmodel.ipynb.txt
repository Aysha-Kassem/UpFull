# ============================================================================
# GRU OPTIMIZED - HIGH PRECISION / RECALL / F1
# ============================================================================

# CELL 1: Install Required Packages
# ----------------------------------------------------------------------------
!pip install -q pandas numpy scikit-learn tensorflow matplotlib seaborn


# CELL 2: Use Existing Dataset in Colab
# ----------------------------------------------------------------------------
import os

filename = "DataSet.csv"

if not os.path.exists(filename):
    raise FileNotFoundError(
        f"ERROR: '{filename}' not found! Please upload it manually to the Colab file explorer."
    )

print(f"âœ“ Using existing file: {filename}")


# CELL 3: Data Preprocessing (Ù†ÙØ³ Ø§Ù„Ù„ÙŠ Ø¹Ù†Ø¯Ùƒ)
# ----------------------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

def prepare_fall_detection_data(filepath='DataSet.csv', time_steps=50, test_size=0.2, random_state=42):
    try:
        df = pd.read_csv(filepath, header=[0, 1])

        df.columns = ['_'.join(col).strip() for col in df.columns.values]
        current_cols = df.columns.tolist()

        wrist_accel_x_col = 'WristAccelerometer_x-axis (g)'
        if wrist_accel_x_col in current_cols:
            x_index = current_cols.index(wrist_accel_x_col)
            df.rename(columns={
                current_cols[x_index + 1]: 'WristAccelerometer_y-axis (g)',
                current_cols[x_index + 2]: 'WristAccelerometer_z-axis (g)',
            }, inplace=True)

        wrist_gyro_x_col = 'WristAngularVelocity_x-axis (deg/s)'
        if wrist_gyro_x_col in current_cols:
            x_index = current_cols.index(wrist_gyro_x_col)
            df.rename(columns={
                current_cols[x_index + 1]: 'WristAngularVelocity_y-axis (deg/s)',
                current_cols[x_index + 2]: 'WristAngularVelocity_z-axis (deg/s)',
            }, inplace=True)

        activity_col = [col for col in df.columns if col.startswith('Activity')][0]

        FEATURE_COLS = [
            'WristAccelerometer_x-axis (g)',
            'WristAccelerometer_y-axis (g)',
            'WristAccelerometer_z-axis (g)',
            'WristAngularVelocity_x-axis (deg/s)',
            'WristAngularVelocity_y-axis (deg/s)',
            'WristAngularVelocity_z-axis (deg/s)'
        ]

        FALL_ACTIVITY_CODES = [7, 8, 9, 10, 11]
        df['Target'] = df[activity_col].apply(lambda x: 1 if x in FALL_ACTIVITY_CODES else 0)

        missing_features = [col for col in FEATURE_COLS if col not in df.columns]
        if missing_features:
            print(f"ERROR: Missing columns: {missing_features}")
            return None, None, None, None

    except Exception as e:
        print(f"Error loading data: {e}")
        return None, None, None, None

    print(f"âœ“ Data loaded. Total samples: {len(df)}")

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[FEATURE_COLS].values)
    y_target = df['Target'].values

    def create_sequences(data, target, time_steps):
        X, y = [], []
        for i in range(len(data) - time_steps):
            X.append(data[i:(i + time_steps), :])
            y.append(target[i + time_steps - 1])
        return np.array(X), np.array(y)

    X_sequences, y_labels = create_sequences(X_scaled, y_target, time_steps)
    print(f"âœ“ Sequences created. Shape: {X_sequences.shape}")

    X_train, X_test, y_train, y_test = train_test_split(
        X_sequences, y_labels,
        test_size=test_size, stratify=y_labels, random_state=random_state
    )

    print(f"âœ“ Train set: {X_train.shape[0]} samples")
    print(f"âœ“ Test set: {X_test.shape[0]} samples")

    return X_train, X_test, y_train, y_test


print("="*60)
print("PREPROCESSING DATA")
print("="*60)

X_train, X_test, y_train, y_test = prepare_fall_detection_data(filename)

if X_train is None:
    raise Exception("Data preprocessing failed!")

print("\nâœ“ Preprocessing complete!")


# CELL 4: Build GRU Model (OPTIMIZED)
# ----------------------------------------------------------------------------
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import regularizers

def build_gru_model(input_shape,
                    gru_units=[64, 32],    # Ø£ÙƒØ¨Ø± Ø´ÙˆÙŠØ© Ù…Ù† Ù‚Ø¨Ù„
                    dropout_rate=0.3,
                    l2_reg=1e-4):
    model = models.Sequential(name='Fall_Detection_GRU_Optimized')

    # Ø·Ø¨Ù‚Ø© GRU Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¹Ø´Ø§Ù† ØªÙ„ØªÙ‚Ø· Ø§Ù„Ø¨Ø§ØªØ±Ù† ÙÙŠ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ÙŠÙ†
    model.add(
        layers.Bidirectional(
            layers.GRU(gru_units[0],
                      return_sequences=True,
                      kernel_regularizer=regularizers.l2(l2_reg)),
            input_shape=input_shape
        )
    )
    model.add(layers.Dropout(dropout_rate))

    # Ø·Ø¨Ù‚Ø© GRU ØªØ§Ù†ÙŠØ©
    model.add(
        layers.GRU(gru_units[1],
                   return_sequences=False,
                   kernel_regularizer=regularizers.l2(l2_reg))
    )
    model.add(layers.Dropout(dropout_rate))

    # Dense Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù‚Ø¯Ø±Ø© Ø§Ù„ØªÙ…Ø«ÙŠÙ„ÙŠØ©
    model.add(layers.Dense(32, activation='relu',
                           kernel_regularizer=regularizers.l2(l2_reg)))
    model.add(layers.Dropout(dropout_rate / 2))

    # Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
    model.add(layers.Dense(1, activation='sigmoid'))

    # Optimizer Ø£Ø­Ø³Ù† (Adam) + clipnorm Ø´ÙˆÙŠØ© Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„ØªØ¯Ø±Ø¬
    optimizer = keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)

    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=[
            'accuracy',
            keras.metrics.Precision(name='precision'),
            keras.metrics.Recall(name='recall')
        ]
    )
    return model


print("="*60)
print("BUILDING OPTIMIZED MODEL")
print("="*60)

input_shape = (X_train.shape[1], X_train.shape[2])
model = build_gru_model(input_shape)

model.summary()
print("\nâœ“ Optimized model built successfully!")


# CELL 5: Train Model (Ù†ÙØ³ Ø§Ù„ÙÙƒØ±Ø© Ù…Ø¹ Ù†ÙØ³ Ø§Ù„Ù€ class weights)
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("TRAINING OPTIMIZED MODEL")
print("="*60)

neg_count = np.sum(y_train == 0)
pos_count = np.sum(y_train == 1)
total = len(y_train)

class_weight = {
    0: total / (2 * neg_count),
    1: total / (2 * pos_count)
}

print(f"Class weights: {class_weight}\n")

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=60,          # Ø¹Ø¯Ø¯ Ø£ÙƒØ¨Ø±ØŒ Ø¨Ø³ EarlyStopping Ù…Ø´ Ù‡ÙŠØ³ÙŠØ¨Ùƒ ØªØ¨Ø§Ù„Øº
    batch_size=64,      # Ù…Ù…ÙƒÙ† ÙŠØ´ØªØºÙ„ Ø£Ø­Ø³Ù† Ù…Ù† 32ØŒ Ø¬Ø±Ù‘Ø¨
    class_weight=class_weight,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

print("\nâœ“ Training complete!")


# CELL 6: Evaluation @ DEFAULT THRESHOLD (0.5)
# ----------------------------------------------------------------------------
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve,
    precision_recall_fscore_support
)
import matplotlib.pyplot as plt
import seaborn as sns

print("\n" + "="*60)
print("MODEL EVALUATION @ THRESHOLD = 0.5")
print("="*60)

y_pred_prob = model.predict(X_test)
y_pred_default = (y_pred_prob > 0.5).astype(int).flatten()

print("\nClassification Report (threshold = 0.5):")
print(classification_report(y_test, y_pred_default, target_names=['Non-Fall', 'Fall'], digits=4))

roc_auc = roc_auc_score(y_test, y_pred_prob)
print(f"\nROC-AUC Score: {roc_auc:.4f}")

cm_default = confusion_matrix(y_test, y_pred_default)
print("\nConfusion Matrix (threshold = 0.5):")
print(cm_default)


# CELL 6b: Find Best Threshold for Highest F1 (Fall class)
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("SEARCHING BEST THRESHOLD FOR MAX F1 (FALL CLASS)")
print("="*60)

best_thr = 0.5
best_f1 = -1
best_prec = 0
best_rec = 0

thresholds = np.linspace(0.1, 0.9, 81)  # Ù…Ù† 0.1 Ù„Ø­Ø¯ 0.9 Ø¨Ø®Ø·ÙˆØ© 0.01 ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§

for thr in thresholds:
    y_pred_thr = (y_pred_prob >= thr).astype(int).flatten()
    prec, rec, f1, _ = precision_recall_fscore_support(
        y_test, y_pred_thr, average=None, labels=[0, 1]
    )
    # index 1 = Ø§Ù„ÙƒÙ„Ø§Ø³ Fall
    fall_prec, fall_rec, fall_f1 = prec[1], rec[1], f1[1]

    if fall_f1 > best_f1:
        best_f1 = fall_f1
        best_thr = thr
        best_prec = fall_prec
        best_rec = fall_rec

print(f"\nBest threshold for FALL F1: {best_thr:.3f}")
print(f"Fall Precision: {best_prec:.4f}")
print(f"Fall Recall   : {best_rec:.4f}")
print(f"Fall F1-Score : {best_f1:.4f}")

# Confusion matrix Ø¹Ù†Ø¯ Ø§Ù„Ù€ threshold Ø§Ù„Ø£ÙØ¶Ù„
y_pred_best = (y_pred_prob >= best_thr).astype(int).flatten()
cm_best = confusion_matrix(y_test, y_pred_best)
print("\nConfusion Matrix (best threshold for FALL F1):")
print(cm_best)


# CELL 7: Visualizations
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("CREATING VISUALIZATIONS")
print("="*60)

fig = plt.figure(figsize=(16, 10))

# 1) Confusion Matrix (default threshold)
plt.subplot(2, 3, 1)
sns.heatmap(cm_default, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Fall', 'Fall'], yticklabels=['Non-Fall', 'Fall'])
plt.title('Confusion Matrix (thr=0.5)')

# 2) Confusion Matrix (best threshold for Fall F1)
plt.subplot(2, 3, 2)
sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Fall', 'Fall'], yticklabels=['Non-Fall', 'Fall'])
plt.title(f'Confusion Matrix (best thr={best_thr:.2f})')

# 3) ROC Curve
plt.subplot(2, 3, 3)
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')
plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend()

# 4) Loss
plt.subplot(2, 3, 4)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('Loss')
plt.legend()

# 5) Accuracy
plt.subplot(2, 3, 5)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy')
plt.legend()

# 6) Precision & Recall (Train/Val)
plt.subplot(2, 3, 6)
plt.plot(history.history['precision'], label='Train Prec')
plt.plot(history.history['val_precision'], label='Val Prec')
plt.plot(history.history['recall'], label='Train Rec')
plt.plot(history.history['val_recall'], label='Val Rec')
plt.title('Precision & Recall')
plt.legend()

plt.tight_layout()
plt.show()

print("\nâœ“ Visualizations complete!")


# CELL 8: Save Model
# ----------------------------------------------------------------------------
print("\n" + "="*60)
print("SAVING MODEL")
print("="*60)

model.save('fall_detection_gru_model_optimized.h5')
print("âœ“ Model saved as fall_detection_gru_model_optimized.h5")

from google.colab import files
files.download('fall_detection_gru_model_optimized.h5')

print("\n" + "="*60)
print("ALL DONE! ðŸŽ‰")
print("="*60)
